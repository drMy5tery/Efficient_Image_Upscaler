# Image Super-Resolution using Enhanced Sub-Pixel Convolutional Networks (ESPCN)

---

## ğŸ“œ Abstract

![Cover Image](Final_PPt/slide_1_img_2.jpeg)

- **Problem Statement:** Super-resolution is crucial in enhancing image quality for applications like:
  - Medical imaging
  - Satellite photos
  - Security

- **Existing Methods:**
  - Traditional Interpolation: Bicubic, Bilinear â€“ Fast but poor quality.
  - State-of-the-Art (e.g., Real-ESRGAN): High quality but computationally expensive.

- **Our Approach:**
  - We implement Efficient ESPCN, balancing performance and speed.
  - Compare results across different scaling factors (2x, 4x, 8x).
  - Compare with and without augmentation for scale=2.

---

## 1. ğŸ“Œ Introduction

![Intro Illustration](Final_PPt/slide_2_img_1.jpeg)

- **Existing Methods:**
  - Bicubic/Bilinear â†’ Simple but low-quality
  - Real-ESRGAN / EDSR â†’ High quality, high cost

- **ESPCN Motivation:**
  - Lightweight, real-time
  - PixelShuffle-based upsampling
  - Suitable for mobile, video, embedded, or web use-cases

---

## 2. ğŸ“‚ Dataset â€“ DIV2K (from Kaggle)

![DIV2K Sample](Final_PPt/slide_3_img_1.jpeg)

- Large, diverse collection of 2K resolution RGB images
- **Training set:** 800 HR images â†’ LR pairs for Ã—2, Ã—4, Ã—8
- **Validation set:** 100 HR images
- **Test set:** 100 diverse images (HR released post-challenge)
- In this project: Only training HR images used to synthesize LR-HR pairs for SR model training.

---

## 3. ğŸ”§ Proposed Methodology

### ğŸ§ª Preprocessing & Augmentation

- Bicubic downsampling to create LR from HR
- Augmentations:
  - `HorizontalFlip(p=0.5)`
  - `RandomBrightnessContrast(p=0.3)`
  - `GaussNoise(var_limit=(5.0, 20.0), p=0.3)`
  - `ImageCompression(quality_lower=85, quality_upper=100, p=0.4)`
  - `RandomGamma(p=0.3)`
  - `HueSaturationValue(p=0.3)`

---

### ğŸ§  ESPCN Model Architecture

![ESPCN Architecture](Final_PPt/slide_6_img_1.jpeg)

- Architecture:
  - `Input â†’ Conv (ReLU) â†’ Conv (ReLU) â†’ Conv â†’ Pixel Shuffle`
- Uses depth-to-space rearrangement for efficient upscaling
- Trained separately for scale=2, 4, 8
- Optimized using Adam
- Loss Function: Mean Squared Error (MSE)

---

## 4. ğŸ“ Evaluation Metrics

### ğŸ”¹ PSNR (Peak Signal-to-Noise Ratio)

- Measures pixel-level fidelity using MSE.
- **Higher = Better** (â‰¥ 30 dB is considered good)
- Limitations:
  - Doesnâ€™t reflect human visual perception
  - Sensitive to pixel-level noise

---

### ğŸ”¸ SSIM (Structural Similarity Index Measure)

- Evaluates:
  - Luminance
  - Contrast
  - Structure
- **Range:** [-1, 1] â†’ closer to 1 = more similar
- Better aligned with human perception than PSNR

---

## 5. ğŸ“Š Results and Comparison

### â–¶ï¸ Without Augmentation

![Results Without Augmentation](Final_PPt/slide_9_img_1.png)

---

### â–¶ï¸ With Augmentation
  
![Results With Augmentation 2](Final_PPt/slide_10_img_2.png)

---

## âœ… Verdict

| Metric | Before Augmentation | After Augmentation | Verdict |
|--------|---------------------|--------------------|---------|
| **MSE** | Low, stable | Low, slightly smoother | Equal / Slightly better |
| **PSNR** | Slightly noisy, larger gap | Smoother, reduced gap | Improved generalization |
| **SSIM** | More variance, lower early on | Smoother, higher convergence | Improved structural quality |

---
